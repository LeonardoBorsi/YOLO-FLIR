{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYIzoXGVImmb",
    "outputId": "1be4cb91-9f18-4027-c8d4-cf6caa440287",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (8.2.31)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (4.10.0.82)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=0.2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ultralytics) (0.2.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pybboxes in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pybboxes) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp312-cp312-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.1/12.1 MB\u001B[0m \u001B[31m30.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.8/301.8 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "%pip install pybboxes\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import array\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO, YOLOWorld, RTDETR\n",
    "from ultralytics.utils.metrics import ConfusionMatrix, Metric, ap_per_class\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from pybboxes import BoundingBox\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37W9aQKTo6TN",
    "outputId": "8d3645b8-56a2-4e30-b222-187c3fc35cb3"
   },
   "outputs": [],
   "source": [
    "dataset_path = 'FLIR_ADAS_v2/video_thermal_test/data'\n",
    "images = sorted(os.listdir(dataset_path))\n",
    "images_paths = [os.path.join(dataset_path, image) for image in images]\n",
    "\n",
    "dataset_classes = {\n",
    "    1: \"person\",\n",
    "    2: \"bike\",\n",
    "    3: \"car\",\n",
    "    4: \"motor\",\n",
    "    6: \"bus\",\n",
    "    7: \"train\",\n",
    "    8: \"truck\",\n",
    "    10: \"light\",\n",
    "    11: \"hydrant\",\n",
    "    12: \"sign\",\n",
    "    17: \"dog\",\n",
    "    37: \"skateboard\",\n",
    "    73: \"stroller\",\n",
    "    77: \"scooter\",\n",
    "    79: \"other vehicle\",\n",
    "    80: \"wrong\"\n",
    "}\n",
    "\n",
    "with open('FLIR_ADAS_v2/video_thermal_test/index.json', 'r') as file:\n",
    "    annotations_data = json.load(file)\n",
    "\n",
    "frames_annotations = annotations_data['frames']\n",
    "\n",
    "yolo_v8 = YOLO('yolov8n.pt')\n",
    "yolo_world = YOLOWorld('yolov8s-world.pt')\n",
    "rt_detr = RTDETR('rtdetr-l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LAl1jSe8onu",
    "outputId": "86af2595-5ebb-4647-ffd7-ab229b48726c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 1 person, 1 airplane, 63.8ms\n",
      "1: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "2: 512x640 1 person, 1 airplane, 63.8ms\n",
      "3: 512x640 1 person, 63.8ms\n",
      "4: 512x640 1 person, 63.8ms\n",
      "5: 512x640 1 person, 63.8ms\n",
      "6: 512x640 1 person, 63.8ms\n",
      "7: 512x640 1 person, 63.8ms\n",
      "8: 512x640 1 person, 1 airplane, 63.8ms\n",
      "9: 512x640 1 person, 63.8ms\n",
      "10: 512x640 1 person, 1 airplane, 63.8ms\n",
      "11: 512x640 1 person, 63.8ms\n",
      "12: 512x640 1 person, 63.8ms\n",
      "13: 512x640 1 person, 63.8ms\n",
      "14: 512x640 1 person, 63.8ms\n",
      "15: 512x640 1 person, 63.8ms\n",
      "16: 512x640 1 person, 1 airplane, 63.8ms\n",
      "17: 512x640 1 person, 63.8ms\n",
      "18: 512x640 1 person, 63.8ms\n",
      "19: 512x640 1 person, 63.8ms\n",
      "20: 512x640 1 person, 1 airplane, 63.8ms\n",
      "21: 512x640 1 person, 63.8ms\n",
      "22: 512x640 1 person, 1 airplane, 63.8ms\n",
      "23: 512x640 (no detections), 63.8ms\n",
      "24: 512x640 1 person, 1 airplane, 63.8ms\n",
      "25: 512x640 1 person, 1 airplane, 63.8ms\n",
      "26: 512x640 1 person, 1 airplane, 63.8ms\n",
      "27: 512x640 1 person, 63.8ms\n",
      "28: 512x640 1 person, 63.8ms\n",
      "29: 512x640 1 person, 1 airplane, 63.8ms\n",
      "30: 512x640 1 person, 63.8ms\n",
      "31: 512x640 1 person, 63.8ms\n",
      "32: 512x640 1 person, 1 airplane, 63.8ms\n",
      "33: 512x640 1 person, 1 airplane, 63.8ms\n",
      "34: 512x640 1 person, 63.8ms\n",
      "35: 512x640 1 person, 63.8ms\n",
      "36: 512x640 1 person, 63.8ms\n",
      "37: 512x640 1 person, 63.8ms\n",
      "38: 512x640 1 person, 63.8ms\n",
      "39: 512x640 1 person, 63.8ms\n",
      "40: 512x640 1 airplane, 63.8ms\n",
      "41: 512x640 1 airplane, 63.8ms\n",
      "42: 512x640 1 person, 1 airplane, 63.8ms\n",
      "43: 512x640 1 person, 1 airplane, 63.8ms\n",
      "44: 512x640 1 airplane, 63.8ms\n",
      "45: 512x640 1 airplane, 63.8ms\n",
      "46: 512x640 1 person, 1 airplane, 63.8ms\n",
      "47: 512x640 1 person, 63.8ms\n",
      "48: 512x640 1 person, 1 airplane, 63.8ms\n",
      "49: 512x640 1 person, 1 airplane, 63.8ms\n",
      "50: 512x640 1 person, 63.8ms\n",
      "51: 512x640 1 person, 63.8ms\n",
      "52: 512x640 1 person, 63.8ms\n",
      "53: 512x640 1 person, 1 airplane, 63.8ms\n",
      "54: 512x640 1 person, 63.8ms\n",
      "55: 512x640 1 person, 1 airplane, 63.8ms\n",
      "56: 512x640 1 person, 1 airplane, 63.8ms\n",
      "57: 512x640 1 person, 1 airplane, 63.8ms\n",
      "58: 512x640 1 person, 63.8ms\n",
      "59: 512x640 1 person, 1 airplane, 63.8ms\n",
      "60: 512x640 1 person, 63.8ms\n",
      "61: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "62: 512x640 1 person, 63.8ms\n",
      "63: 512x640 1 person, 63.8ms\n",
      "64: 512x640 1 person, 63.8ms\n",
      "65: 512x640 1 person, 1 airplane, 63.8ms\n",
      "66: 512x640 1 person, 63.8ms\n",
      "67: 512x640 1 person, 63.8ms\n",
      "68: 512x640 1 person, 63.8ms\n",
      "69: 512x640 1 person, 63.8ms\n",
      "70: 512x640 1 person, 1 airplane, 63.8ms\n",
      "71: 512x640 1 person, 1 airplane, 63.8ms\n",
      "72: 512x640 1 person, 1 airplane, 63.8ms\n",
      "73: 512x640 1 person, 63.8ms\n",
      "74: 512x640 1 person, 1 airplane, 63.8ms\n",
      "75: 512x640 1 person, 63.8ms\n",
      "76: 512x640 1 person, 1 airplane, 63.8ms\n",
      "77: 512x640 1 person, 63.8ms\n",
      "78: 512x640 1 person, 63.8ms\n",
      "79: 512x640 1 person, 63.8ms\n",
      "80: 512x640 1 person, 1 airplane, 63.8ms\n",
      "81: 512x640 1 person, 1 airplane, 63.8ms\n",
      "82: 512x640 1 person, 63.8ms\n",
      "83: 512x640 1 person, 1 airplane, 63.8ms\n",
      "84: 512x640 1 person, 1 airplane, 63.8ms\n",
      "85: 512x640 1 person, 63.8ms\n",
      "86: 512x640 1 person, 1 airplane, 63.8ms\n",
      "87: 512x640 1 person, 63.8ms\n",
      "88: 512x640 1 person, 63.8ms\n",
      "89: 512x640 1 person, 63.8ms\n",
      "90: 512x640 1 person, 1 airplane, 63.8ms\n",
      "91: 512x640 1 person, 63.8ms\n",
      "92: 512x640 1 person, 1 airplane, 63.8ms\n",
      "93: 512x640 1 person, 63.8ms\n",
      "94: 512x640 1 person, 63.8ms\n",
      "95: 512x640 1 person, 63.8ms\n",
      "96: 512x640 1 airplane, 63.8ms\n",
      "97: 512x640 1 person, 1 airplane, 63.8ms\n",
      "98: 512x640 1 airplane, 63.8ms\n",
      "99: 512x640 1 person, 1 airplane, 63.8ms\n",
      "100: 512x640 1 person, 1 airplane, 63.8ms\n",
      "101: 512x640 1 person, 63.8ms\n",
      "102: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "103: 512x640 1 person, 63.8ms\n",
      "104: 512x640 1 person, 63.8ms\n",
      "105: 512x640 1 airplane, 63.8ms\n",
      "106: 512x640 (no detections), 63.8ms\n",
      "107: 512x640 1 person, 63.8ms\n",
      "108: 512x640 1 airplane, 63.8ms\n",
      "109: 512x640 1 person, 1 airplane, 63.8ms\n",
      "110: 512x640 1 person, 63.8ms\n",
      "111: 512x640 1 person, 1 airplane, 63.8ms\n",
      "112: 512x640 1 person, 1 airplane, 63.8ms\n",
      "113: 512x640 1 person, 63.8ms\n",
      "114: 512x640 1 person, 63.8ms\n",
      "115: 512x640 1 person, 1 airplane, 63.8ms\n",
      "116: 512x640 1 person, 63.8ms\n",
      "117: 512x640 1 person, 63.8ms\n",
      "118: 512x640 1 airplane, 63.8ms\n",
      "119: 512x640 1 person, 1 airplane, 63.8ms\n",
      "120: 512x640 (no detections), 63.8ms\n",
      "121: 512x640 1 person, 63.8ms\n",
      "122: 512x640 1 person, 63.8ms\n",
      "123: 512x640 1 person, 63.8ms\n",
      "124: 512x640 1 person, 1 airplane, 63.8ms\n",
      "125: 512x640 1 person, 63.8ms\n",
      "126: 512x640 1 person, 63.8ms\n",
      "127: 512x640 1 person, 63.8ms\n",
      "128: 512x640 1 person, 1 airplane, 63.8ms\n",
      "129: 512x640 1 airplane, 63.8ms\n",
      "130: 512x640 1 person, 1 airplane, 63.8ms\n",
      "131: 512x640 1 person, 1 airplane, 63.8ms\n",
      "132: 512x640 1 person, 63.8ms\n",
      "133: 512x640 1 person, 1 airplane, 63.8ms\n",
      "134: 512x640 1 person, 63.8ms\n",
      "135: 512x640 1 person, 63.8ms\n",
      "136: 512x640 1 person, 1 airplane, 63.8ms\n",
      "137: 512x640 2 persons, 1 airplane, 63.8ms\n",
      "138: 512x640 1 person, 1 airplane, 63.8ms\n",
      "139: 512x640 1 person, 1 airplane, 63.8ms\n",
      "140: 512x640 1 person, 63.8ms\n",
      "141: 512x640 1 person, 63.8ms\n",
      "142: 512x640 1 person, 63.8ms\n",
      "143: 512x640 1 person, 1 airplane, 63.8ms\n",
      "144: 512x640 1 person, 1 airplane, 63.8ms\n",
      "145: 512x640 1 person, 63.8ms\n",
      "146: 512x640 1 person, 1 airplane, 63.8ms\n",
      "147: 512x640 1 person, 63.8ms\n",
      "148: 512x640 1 person, 63.8ms\n",
      "149: 512x640 1 person, 1 airplane, 63.8ms\n",
      "150: 512x640 1 person, 1 airplane, 63.8ms\n",
      "151: 512x640 1 person, 63.8ms\n",
      "152: 512x640 1 person, 63.8ms\n",
      "153: 512x640 1 person, 63.8ms\n",
      "154: 512x640 1 person, 1 airplane, 63.8ms\n",
      "155: 512x640 1 person, 63.8ms\n",
      "156: 512x640 1 person, 1 airplane, 63.8ms\n",
      "157: 512x640 1 person, 63.8ms\n",
      "158: 512x640 1 person, 63.8ms\n",
      "159: 512x640 1 person, 1 airplane, 63.8ms\n",
      "160: 512x640 1 person, 1 airplane, 63.8ms\n",
      "161: 512x640 1 person, 1 airplane, 63.8ms\n",
      "162: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "163: 512x640 1 person, 1 airplane, 63.8ms\n",
      "164: 512x640 1 person, 1 airplane, 63.8ms\n",
      "165: 512x640 1 person, 1 airplane, 63.8ms\n",
      "166: 512x640 1 person, 63.8ms\n",
      "167: 512x640 1 person, 63.8ms\n",
      "168: 512x640 1 person, 1 airplane, 63.8ms\n",
      "169: 512x640 1 person, 1 airplane, 63.8ms\n",
      "170: 512x640 1 person, 63.8ms\n",
      "171: 512x640 1 person, 63.8ms\n",
      "172: 512x640 1 person, 63.8ms\n",
      "173: 512x640 1 person, 1 airplane, 63.8ms\n",
      "174: 512x640 2 persons, 2 airplanes, 63.8ms\n",
      "175: 512x640 2 persons, 63.8ms\n",
      "176: 512x640 1 person, 1 airplane, 63.8ms\n",
      "177: 512x640 1 person, 1 airplane, 63.8ms\n",
      "178: 512x640 3 persons, 1 airplane, 63.8ms\n",
      "179: 512x640 2 persons, 1 airplane, 63.8ms\n",
      "180: 512x640 1 person, 1 airplane, 63.8ms\n",
      "181: 512x640 2 persons, 1 airplane, 63.8ms\n",
      "182: 512x640 2 persons, 1 airplane, 63.8ms\n",
      "183: 512x640 2 persons, 1 airplane, 63.8ms\n",
      "184: 512x640 1 person, 1 airplane, 63.8ms\n",
      "185: 512x640 1 person, 1 airplane, 63.8ms\n",
      "186: 512x640 1 person, 63.8ms\n",
      "187: 512x640 1 person, 63.8ms\n",
      "188: 512x640 2 persons, 2 airplanes, 63.8ms\n",
      "189: 512x640 1 person, 63.8ms\n",
      "190: 512x640 1 person, 1 airplane, 63.8ms\n",
      "191: 512x640 1 person, 1 airplane, 63.8ms\n",
      "192: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "193: 512x640 1 person, 63.8ms\n",
      "194: 512x640 1 person, 1 airplane, 63.8ms\n",
      "195: 512x640 1 person, 1 airplane, 63.8ms\n",
      "196: 512x640 1 person, 1 airplane, 63.8ms\n",
      "197: 512x640 1 person, 63.8ms\n",
      "198: 512x640 1 person, 63.8ms\n",
      "199: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "200: 512x640 1 person, 1 airplane, 63.8ms\n",
      "201: 512x640 1 person, 1 airplane, 63.8ms\n",
      "202: 512x640 1 person, 63.8ms\n",
      "203: 512x640 1 person, 63.8ms\n",
      "204: 512x640 1 person, 63.8ms\n",
      "205: 512x640 1 person, 63.8ms\n",
      "206: 512x640 1 person, 1 airplane, 63.8ms\n",
      "207: 512x640 1 person, 63.8ms\n",
      "208: 512x640 1 person, 1 airplane, 63.8ms\n",
      "209: 512x640 1 person, 1 airplane, 63.8ms\n",
      "210: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "211: 512x640 1 person, 1 airplane, 63.8ms\n",
      "212: 512x640 1 person, 63.8ms\n",
      "213: 512x640 1 person, 63.8ms\n",
      "214: 512x640 1 person, 63.8ms\n",
      "215: 512x640 1 person, 63.8ms\n",
      "216: 512x640 1 person, 1 airplane, 63.8ms\n",
      "217: 512x640 1 person, 1 airplane, 63.8ms\n",
      "218: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "219: 512x640 1 person, 63.8ms\n",
      "220: 512x640 1 person, 1 airplane, 63.8ms\n",
      "221: 512x640 1 person, 1 airplane, 63.8ms\n",
      "222: 512x640 1 person, 1 airplane, 63.8ms\n",
      "223: 512x640 1 person, 1 airplane, 63.8ms\n",
      "224: 512x640 1 person, 1 airplane, 63.8ms\n",
      "225: 512x640 1 person, 1 airplane, 63.8ms\n",
      "226: 512x640 2 persons, 63.8ms\n",
      "227: 512x640 2 persons, 63.8ms\n",
      "228: 512x640 2 persons, 63.8ms\n",
      "229: 512x640 1 person, 1 airplane, 63.8ms\n",
      "230: 512x640 1 person, 1 airplane, 63.8ms\n",
      "231: 512x640 1 person, 63.8ms\n",
      "232: 512x640 1 person, 1 airplane, 63.8ms\n",
      "233: 512x640 2 persons, 63.8ms\n",
      "234: 512x640 1 person, 63.8ms\n",
      "235: 512x640 1 person, 63.8ms\n",
      "236: 512x640 1 person, 1 airplane, 63.8ms\n",
      "237: 512x640 1 person, 63.8ms\n",
      "238: 512x640 1 person, 63.8ms\n",
      "239: 512x640 1 person, 2 airplanes, 63.8ms\n",
      "240: 512x640 1 person, 63.8ms\n",
      "241: 512x640 1 person, 1 airplane, 63.8ms\n",
      "242: 512x640 1 person, 63.8ms\n",
      "243: 512x640 1 person, 63.8ms\n",
      "244: 512x640 1 person, 63.8ms\n",
      "245: 512x640 1 person, 63.8ms\n",
      "246: 512x640 1 person, 63.8ms\n",
      "247: 512x640 1 person, 63.8ms\n",
      "248: 512x640 1 person, 63.8ms\n",
      "249: 512x640 1 person, 1 airplane, 63.8ms\n",
      "Speed: 3.0ms preprocess, 63.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 1 person, 212.3ms\n",
      "1: 512x640 1 person, 212.3ms\n",
      "2: 512x640 1 person, 212.3ms\n",
      "3: 512x640 1 person, 212.3ms\n",
      "4: 512x640 1 person, 212.3ms\n",
      "5: 512x640 1 person, 212.3ms\n",
      "6: 512x640 1 person, 212.3ms\n",
      "7: 512x640 1 person, 212.3ms\n",
      "8: 512x640 1 person, 212.3ms\n",
      "9: 512x640 1 person, 212.3ms\n",
      "10: 512x640 1 person, 212.3ms\n",
      "11: 512x640 1 person, 212.3ms\n",
      "12: 512x640 1 person, 212.3ms\n",
      "13: 512x640 1 person, 212.3ms\n",
      "14: 512x640 1 person, 212.3ms\n",
      "15: 512x640 1 person, 1 car, 212.3ms\n",
      "16: 512x640 1 person, 212.3ms\n",
      "17: 512x640 1 person, 212.3ms\n",
      "18: 512x640 1 person, 212.3ms\n",
      "19: 512x640 1 person, 212.3ms\n",
      "20: 512x640 1 person, 212.3ms\n",
      "21: 512x640 1 person, 212.3ms\n",
      "22: 512x640 1 person, 212.3ms\n",
      "23: 512x640 1 person, 212.3ms\n",
      "24: 512x640 1 person, 212.3ms\n",
      "25: 512x640 1 person, 1 car, 212.3ms\n",
      "26: 512x640 1 person, 212.3ms\n",
      "27: 512x640 1 person, 212.3ms\n",
      "28: 512x640 1 person, 212.3ms\n",
      "29: 512x640 1 person, 212.3ms\n",
      "30: 512x640 1 person, 212.3ms\n",
      "31: 512x640 1 person, 212.3ms\n",
      "32: 512x640 1 person, 212.3ms\n",
      "33: 512x640 1 person, 212.3ms\n",
      "34: 512x640 1 person, 212.3ms\n",
      "35: 512x640 1 person, 212.3ms\n",
      "36: 512x640 1 person, 212.3ms\n",
      "37: 512x640 1 person, 212.3ms\n",
      "38: 512x640 1 person, 212.3ms\n",
      "39: 512x640 1 person, 212.3ms\n",
      "40: 512x640 1 person, 212.3ms\n",
      "41: 512x640 2 persons, 212.3ms\n",
      "42: 512x640 1 person, 212.3ms\n",
      "43: 512x640 1 person, 212.3ms\n",
      "44: 512x640 1 person, 212.3ms\n",
      "45: 512x640 1 person, 1 car, 212.3ms\n",
      "46: 512x640 1 person, 212.3ms\n",
      "47: 512x640 1 person, 1 car, 212.3ms\n",
      "48: 512x640 1 person, 212.3ms\n",
      "49: 512x640 1 person, 212.3ms\n",
      "50: 512x640 1 person, 212.3ms\n",
      "51: 512x640 1 person, 212.3ms\n",
      "52: 512x640 1 person, 212.3ms\n",
      "53: 512x640 1 person, 212.3ms\n",
      "54: 512x640 1 person, 212.3ms\n",
      "55: 512x640 1 person, 212.3ms\n",
      "56: 512x640 1 person, 212.3ms\n",
      "57: 512x640 1 person, 212.3ms\n",
      "58: 512x640 1 person, 212.3ms\n",
      "59: 512x640 1 person, 212.3ms\n",
      "60: 512x640 1 person, 212.3ms\n",
      "61: 512x640 1 person, 212.3ms\n",
      "62: 512x640 1 person, 212.3ms\n",
      "63: 512x640 1 person, 212.3ms\n",
      "64: 512x640 1 person, 212.3ms\n",
      "65: 512x640 1 person, 212.3ms\n",
      "66: 512x640 1 person, 212.3ms\n",
      "67: 512x640 1 person, 212.3ms\n",
      "68: 512x640 1 person, 212.3ms\n",
      "69: 512x640 1 person, 212.3ms\n",
      "70: 512x640 1 person, 212.3ms\n",
      "71: 512x640 1 person, 212.3ms\n",
      "72: 512x640 1 person, 212.3ms\n",
      "73: 512x640 1 person, 212.3ms\n",
      "74: 512x640 (no detections), 212.3ms\n",
      "75: 512x640 1 person, 212.3ms\n",
      "76: 512x640 1 person, 212.3ms\n",
      "77: 512x640 1 person, 212.3ms\n",
      "78: 512x640 1 person, 212.3ms\n",
      "79: 512x640 1 person, 212.3ms\n",
      "80: 512x640 1 person, 212.3ms\n",
      "81: 512x640 1 person, 212.3ms\n",
      "82: 512x640 1 person, 212.3ms\n",
      "83: 512x640 1 person, 212.3ms\n",
      "84: 512x640 1 person, 212.3ms\n",
      "85: 512x640 1 person, 212.3ms\n",
      "86: 512x640 1 person, 212.3ms\n",
      "87: 512x640 1 person, 212.3ms\n",
      "88: 512x640 1 person, 212.3ms\n",
      "89: 512x640 1 person, 212.3ms\n",
      "90: 512x640 1 person, 212.3ms\n",
      "91: 512x640 1 person, 212.3ms\n",
      "92: 512x640 1 person, 212.3ms\n",
      "93: 512x640 1 person, 212.3ms\n",
      "94: 512x640 1 person, 212.3ms\n",
      "95: 512x640 1 person, 212.3ms\n",
      "96: 512x640 1 person, 212.3ms\n",
      "97: 512x640 1 person, 212.3ms\n",
      "98: 512x640 1 person, 1 car, 212.3ms\n",
      "99: 512x640 1 person, 212.3ms\n",
      "100: 512x640 1 person, 212.3ms\n",
      "101: 512x640 1 person, 212.3ms\n",
      "102: 512x640 1 person, 212.3ms\n",
      "103: 512x640 1 person, 212.3ms\n",
      "104: 512x640 1 person, 212.3ms\n",
      "105: 512x640 1 person, 212.3ms\n",
      "106: 512x640 1 person, 212.3ms\n",
      "107: 512x640 1 person, 212.3ms\n",
      "108: 512x640 1 person, 212.3ms\n",
      "109: 512x640 1 person, 212.3ms\n",
      "110: 512x640 1 person, 212.3ms\n",
      "111: 512x640 1 person, 212.3ms\n",
      "112: 512x640 1 person, 212.3ms\n",
      "113: 512x640 1 person, 212.3ms\n",
      "114: 512x640 1 person, 212.3ms\n",
      "115: 512x640 1 person, 212.3ms\n",
      "116: 512x640 1 person, 212.3ms\n",
      "117: 512x640 1 person, 212.3ms\n",
      "118: 512x640 1 person, 212.3ms\n",
      "119: 512x640 1 person, 212.3ms\n",
      "120: 512x640 1 person, 212.3ms\n",
      "121: 512x640 1 person, 212.3ms\n",
      "122: 512x640 1 person, 212.3ms\n",
      "123: 512x640 1 person, 212.3ms\n",
      "124: 512x640 1 person, 212.3ms\n",
      "125: 512x640 1 person, 212.3ms\n",
      "126: 512x640 1 person, 212.3ms\n",
      "127: 512x640 1 person, 212.3ms\n",
      "128: 512x640 1 person, 212.3ms\n",
      "129: 512x640 1 person, 212.3ms\n",
      "130: 512x640 1 person, 212.3ms\n",
      "131: 512x640 1 person, 212.3ms\n",
      "132: 512x640 1 person, 212.3ms\n",
      "133: 512x640 1 person, 212.3ms\n",
      "134: 512x640 1 person, 212.3ms\n",
      "135: 512x640 1 person, 212.3ms\n",
      "136: 512x640 1 person, 212.3ms\n",
      "137: 512x640 1 person, 212.3ms\n",
      "138: 512x640 1 person, 212.3ms\n",
      "139: 512x640 1 person, 212.3ms\n",
      "140: 512x640 1 person, 212.3ms\n",
      "141: 512x640 1 person, 212.3ms\n",
      "142: 512x640 1 person, 212.3ms\n",
      "143: 512x640 1 person, 212.3ms\n",
      "144: 512x640 1 person, 212.3ms\n",
      "145: 512x640 1 person, 212.3ms\n",
      "146: 512x640 1 person, 212.3ms\n",
      "147: 512x640 1 person, 212.3ms\n",
      "148: 512x640 1 person, 212.3ms\n",
      "149: 512x640 1 person, 212.3ms\n",
      "150: 512x640 1 person, 212.3ms\n",
      "151: 512x640 1 person, 212.3ms\n",
      "152: 512x640 1 person, 212.3ms\n",
      "153: 512x640 1 person, 212.3ms\n",
      "154: 512x640 1 person, 212.3ms\n",
      "155: 512x640 1 person, 212.3ms\n",
      "156: 512x640 1 person, 212.3ms\n",
      "157: 512x640 1 person, 212.3ms\n",
      "158: 512x640 1 person, 212.3ms\n",
      "159: 512x640 1 person, 212.3ms\n",
      "160: 512x640 1 person, 212.3ms\n",
      "161: 512x640 1 person, 212.3ms\n",
      "162: 512x640 1 person, 212.3ms\n",
      "163: 512x640 1 person, 212.3ms\n",
      "164: 512x640 1 person, 212.3ms\n",
      "165: 512x640 1 person, 212.3ms\n",
      "166: 512x640 1 person, 212.3ms\n",
      "167: 512x640 1 person, 212.3ms\n",
      "168: 512x640 1 person, 212.3ms\n",
      "169: 512x640 1 person, 212.3ms\n",
      "170: 512x640 1 person, 212.3ms\n",
      "171: 512x640 1 person, 212.3ms\n",
      "172: 512x640 1 person, 212.3ms\n",
      "173: 512x640 1 person, 212.3ms\n",
      "174: 512x640 1 person, 212.3ms\n",
      "175: 512x640 1 person, 212.3ms\n",
      "176: 512x640 1 person, 212.3ms\n",
      "177: 512x640 1 person, 212.3ms\n",
      "178: 512x640 1 person, 212.3ms\n",
      "179: 512x640 1 person, 212.3ms\n",
      "180: 512x640 1 person, 212.3ms\n",
      "181: 512x640 2 persons, 212.3ms\n",
      "182: 512x640 2 persons, 212.3ms\n",
      "183: 512x640 2 persons, 212.3ms\n",
      "184: 512x640 1 person, 212.3ms\n",
      "185: 512x640 1 person, 212.3ms\n",
      "186: 512x640 1 person, 212.3ms\n",
      "187: 512x640 1 person, 212.3ms\n",
      "188: 512x640 1 person, 212.3ms\n",
      "189: 512x640 1 person, 212.3ms\n",
      "190: 512x640 1 person, 212.3ms\n",
      "191: 512x640 1 person, 212.3ms\n",
      "192: 512x640 1 person, 212.3ms\n",
      "193: 512x640 2 persons, 212.3ms\n",
      "194: 512x640 1 person, 212.3ms\n",
      "195: 512x640 1 person, 212.3ms\n",
      "196: 512x640 1 person, 212.3ms\n",
      "197: 512x640 1 person, 212.3ms\n",
      "198: 512x640 1 person, 212.3ms\n",
      "199: 512x640 1 person, 212.3ms\n",
      "200: 512x640 1 person, 212.3ms\n",
      "201: 512x640 1 person, 212.3ms\n",
      "202: 512x640 1 person, 212.3ms\n",
      "203: 512x640 1 person, 212.3ms\n",
      "204: 512x640 1 person, 212.3ms\n",
      "205: 512x640 1 person, 212.3ms\n",
      "206: 512x640 1 person, 212.3ms\n",
      "207: 512x640 1 person, 212.3ms\n",
      "208: 512x640 1 person, 212.3ms\n",
      "209: 512x640 1 person, 212.3ms\n",
      "210: 512x640 1 person, 212.3ms\n",
      "211: 512x640 1 person, 212.3ms\n",
      "212: 512x640 1 person, 212.3ms\n",
      "213: 512x640 1 person, 212.3ms\n",
      "214: 512x640 1 person, 212.3ms\n",
      "215: 512x640 1 person, 212.3ms\n",
      "216: 512x640 2 persons, 212.3ms\n",
      "217: 512x640 1 person, 212.3ms\n",
      "218: 512x640 1 person, 212.3ms\n",
      "219: 512x640 1 person, 212.3ms\n",
      "220: 512x640 1 person, 212.3ms\n",
      "221: 512x640 1 person, 212.3ms\n",
      "222: 512x640 1 person, 212.3ms\n",
      "223: 512x640 1 person, 212.3ms\n",
      "224: 512x640 1 person, 212.3ms\n",
      "225: 512x640 1 person, 212.3ms\n",
      "226: 512x640 1 person, 212.3ms\n",
      "227: 512x640 1 person, 212.3ms\n",
      "228: 512x640 1 person, 212.3ms\n",
      "229: 512x640 1 person, 212.3ms\n",
      "230: 512x640 1 person, 212.3ms\n",
      "231: 512x640 1 person, 212.3ms\n",
      "232: 512x640 2 persons, 212.3ms\n",
      "233: 512x640 2 persons, 212.3ms\n",
      "234: 512x640 1 person, 212.3ms\n",
      "235: 512x640 1 person, 212.3ms\n",
      "236: 512x640 1 person, 212.3ms\n",
      "237: 512x640 1 person, 212.3ms\n",
      "238: 512x640 1 person, 212.3ms\n",
      "239: 512x640 1 person, 212.3ms\n",
      "240: 512x640 1 person, 212.3ms\n",
      "241: 512x640 1 person, 212.3ms\n",
      "242: 512x640 1 person, 212.3ms\n",
      "243: 512x640 1 person, 212.3ms\n",
      "244: 512x640 1 person, 212.3ms\n",
      "245: 512x640 1 person, 212.3ms\n",
      "246: 512x640 1 person, 212.3ms\n",
      "247: 512x640 1 person, 212.3ms\n",
      "248: 512x640 1 person, 212.3ms\n",
      "249: 512x640 1 person, 212.3ms\n",
      "Speed: 2.9ms preprocess, 212.3ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1344.0ms\n",
      "1: 640x640 2 persons, 1344.0ms\n",
      "2: 640x640 2 persons, 1344.0ms\n",
      "3: 640x640 1 person, 1 car, 1344.0ms\n",
      "4: 640x640 1 person, 1 car, 1344.0ms\n",
      "5: 640x640 1 person, 1 car, 1344.0ms\n",
      "6: 640x640 1 person, 1344.0ms\n",
      "7: 640x640 1 person, 1344.0ms\n",
      "8: 640x640 2 persons, 1 car, 1344.0ms\n",
      "9: 640x640 1 person, 1 car, 1344.0ms\n",
      "10: 640x640 1 person, 1 car, 1344.0ms\n",
      "11: 640x640 1 person, 1344.0ms\n",
      "12: 640x640 1 person, 1 car, 1344.0ms\n",
      "13: 640x640 1 person, 1344.0ms\n",
      "14: 640x640 1 person, 1 car, 1 truck, 1344.0ms\n",
      "15: 640x640 1 person, 1 car, 1344.0ms\n",
      "16: 640x640 1 person, 1344.0ms\n",
      "17: 640x640 1 person, 1344.0ms\n",
      "18: 640x640 1 person, 1 car, 1344.0ms\n",
      "19: 640x640 1 person, 1 car, 1344.0ms\n",
      "20: 640x640 1 person, 1 car, 1344.0ms\n",
      "21: 640x640 1 person, 1344.0ms\n",
      "22: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "23: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "24: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "25: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "26: 640x640 2 persons, 1 car, 1344.0ms\n",
      "27: 640x640 1 person, 1344.0ms\n",
      "28: 640x640 1 person, 1 car, 1344.0ms\n",
      "29: 640x640 1 person, 1 car, 1344.0ms\n",
      "30: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "31: 640x640 1 person, 1344.0ms\n",
      "32: 640x640 1 person, 1 car, 1344.0ms\n",
      "33: 640x640 2 persons, 1 car, 1344.0ms\n",
      "34: 640x640 2 persons, 1 car, 1344.0ms\n",
      "35: 640x640 2 persons, 1 car, 1344.0ms\n",
      "36: 640x640 1 person, 1344.0ms\n",
      "37: 640x640 1 person, 1344.0ms\n",
      "38: 640x640 3 persons, 1344.0ms\n",
      "39: 640x640 1 person, 1 car, 1344.0ms\n",
      "40: 640x640 1 person, 1344.0ms\n",
      "41: 640x640 2 persons, 1 car, 1344.0ms\n",
      "42: 640x640 1 person, 1344.0ms\n",
      "43: 640x640 1 person, 1344.0ms\n",
      "44: 640x640 2 persons, 1344.0ms\n",
      "45: 640x640 3 persons, 1 car, 1344.0ms\n",
      "46: 640x640 1 person, 1 car, 1344.0ms\n",
      "47: 640x640 2 persons, 1 car, 1344.0ms\n",
      "48: 640x640 3 persons, 1 car, 1344.0ms\n",
      "49: 640x640 2 persons, 1 car, 1344.0ms\n",
      "50: 640x640 2 persons, 1 car, 1344.0ms\n",
      "51: 640x640 1 person, 1344.0ms\n",
      "52: 640x640 2 persons, 1344.0ms\n",
      "53: 640x640 1 person, 1344.0ms\n",
      "54: 640x640 1 person, 1344.0ms\n",
      "55: 640x640 1 person, 1 car, 1344.0ms\n",
      "56: 640x640 1 person, 1 car, 1344.0ms\n",
      "57: 640x640 3 persons, 1 car, 1344.0ms\n",
      "58: 640x640 2 persons, 1344.0ms\n",
      "59: 640x640 2 persons, 1344.0ms\n",
      "60: 640x640 2 persons, 1344.0ms\n",
      "61: 640x640 1 person, 1 car, 1344.0ms\n",
      "62: 640x640 1 person, 1 car, 1344.0ms\n",
      "63: 640x640 1 person, 1 car, 1344.0ms\n",
      "64: 640x640 1 person, 1 car, 1344.0ms\n",
      "65: 640x640 2 persons, 1 car, 1344.0ms\n",
      "66: 640x640 2 persons, 1344.0ms\n",
      "67: 640x640 2 persons, 1344.0ms\n",
      "68: 640x640 1 person, 1344.0ms\n",
      "69: 640x640 2 persons, 1 car, 1344.0ms\n",
      "70: 640x640 3 persons, 1 car, 1344.0ms\n",
      "71: 640x640 3 persons, 1 car, 1344.0ms\n",
      "72: 640x640 1 person, 1344.0ms\n",
      "73: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "74: 640x640 1 person, 2 cars, 1344.0ms\n",
      "75: 640x640 3 cars, 1 fire hydrant, 1344.0ms\n",
      "76: 640x640 1 person, 1344.0ms\n",
      "77: 640x640 1 person, 1344.0ms\n",
      "78: 640x640 1 person, 1 car, 1344.0ms\n",
      "79: 640x640 1 person, 1 car, 1344.0ms\n",
      "80: 640x640 1 person, 1344.0ms\n",
      "81: 640x640 1 person, 1 car, 1344.0ms\n",
      "82: 640x640 1 person, 1344.0ms\n",
      "83: 640x640 1 person, 1 car, 1344.0ms\n",
      "84: 640x640 1 person, 2 cars, 1344.0ms\n",
      "85: 640x640 1 person, 1 car, 1344.0ms\n",
      "86: 640x640 2 cars, 1 fire hydrant, 1344.0ms\n",
      "87: 640x640 1 fire hydrant, 1344.0ms\n",
      "88: 640x640 1 person, 1344.0ms\n",
      "89: 640x640 1 person, 2 cars, 1344.0ms\n",
      "90: 640x640 2 persons, 1 baseball glove, 1344.0ms\n",
      "91: 640x640 1 person, 2 cars, 1344.0ms\n",
      "92: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "93: 640x640 1 person, 1 car, 1 baseball glove, 1344.0ms\n",
      "94: 640x640 1 person, 1 car, 1 baseball glove, 1344.0ms\n",
      "95: 640x640 1 person, 1344.0ms\n",
      "96: 640x640 1 person, 1 car, 1344.0ms\n",
      "97: 640x640 1 person, 1 car, 1344.0ms\n",
      "98: 640x640 1 person, 1 car, 1344.0ms\n",
      "99: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "100: 640x640 1 fire hydrant, 1344.0ms\n",
      "101: 640x640 1 fire hydrant, 1344.0ms\n",
      "102: 640x640 1 person, 1 car, 1344.0ms\n",
      "103: 640x640 1 person, 1344.0ms\n",
      "104: 640x640 1 person, 1 car, 1344.0ms\n",
      "105: 640x640 1 person, 1344.0ms\n",
      "106: 640x640 1 person, 1344.0ms\n",
      "107: 640x640 1 person, 1344.0ms\n",
      "108: 640x640 1 person, 1344.0ms\n",
      "109: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "110: 640x640 1 person, 1 car, 1344.0ms\n",
      "111: 640x640 1 person, 1 car, 1344.0ms\n",
      "112: 640x640 1 person, 1344.0ms\n",
      "113: 640x640 2 persons, 1 car, 1344.0ms\n",
      "114: 640x640 1 person, 1 sports ball, 1344.0ms\n",
      "115: 640x640 1 person, 1 sports ball, 1 baseball glove, 1344.0ms\n",
      "116: 640x640 1 person, 1 sports ball, 1344.0ms\n",
      "117: 640x640 1 person, 1344.0ms\n",
      "118: 640x640 2 persons, 1 car, 1344.0ms\n",
      "119: 640x640 1 person, 1344.0ms\n",
      "120: 640x640 1 person, 1344.0ms\n",
      "121: 640x640 1 fire hydrant, 1344.0ms\n",
      "122: 640x640 2 persons, 1344.0ms\n",
      "123: 640x640 2 cars, 1 fire hydrant, 1344.0ms\n",
      "124: 640x640 1 person, 1344.0ms\n",
      "125: 640x640 2 persons, 1344.0ms\n",
      "126: 640x640 1 person, 2 cars, 1344.0ms\n",
      "127: 640x640 1 person, 1 sports ball, 1344.0ms\n",
      "128: 640x640 1 person, 1344.0ms\n",
      "129: 640x640 1 person, 1 sports ball, 1344.0ms\n",
      "130: 640x640 1 person, 1344.0ms\n",
      "131: 640x640 1 person, 1 car, 1344.0ms\n",
      "132: 640x640 3 persons, 1344.0ms\n",
      "133: 640x640 1 person, 1 car, 1344.0ms\n",
      "134: 640x640 1 person, 2 cars, 1344.0ms\n",
      "135: 640x640 1 person, 2 cars, 1344.0ms\n",
      "136: 640x640 1 person, 1344.0ms\n",
      "137: 640x640 1 person, 1 car, 1344.0ms\n",
      "138: 640x640 1 person, 1344.0ms\n",
      "139: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "140: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "141: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "142: 640x640 1 person, 1344.0ms\n",
      "143: 640x640 1 fire hydrant, 1344.0ms\n",
      "144: 640x640 1 person, 1344.0ms\n",
      "145: 640x640 1 person, 1344.0ms\n",
      "146: 640x640 1 person, 1344.0ms\n",
      "147: 640x640 1 person, 1344.0ms\n",
      "148: 640x640 1 person, 1 car, 1344.0ms\n",
      "149: 640x640 1 person, 1344.0ms\n",
      "150: 640x640 1 person, 1344.0ms\n",
      "151: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "152: 640x640 1 person, 1344.0ms\n",
      "153: 640x640 1 person, 1344.0ms\n",
      "154: 640x640 1 person, 1344.0ms\n",
      "155: 640x640 1 person, 1 car, 1344.0ms\n",
      "156: 640x640 1 person, 1344.0ms\n",
      "157: 640x640 1 person, 1344.0ms\n",
      "158: 640x640 1 person, 1344.0ms\n",
      "159: 640x640 1 fire hydrant, 1344.0ms\n",
      "160: 640x640 1 person, 1344.0ms\n",
      "161: 640x640 2 persons, 1344.0ms\n",
      "162: 640x640 1 person, 1344.0ms\n",
      "163: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "164: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "165: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "166: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "167: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "168: 640x640 1 person, 1344.0ms\n",
      "169: 640x640 1 person, 1344.0ms\n",
      "170: 640x640 1 person, 1344.0ms\n",
      "171: 640x640 1 person, 1344.0ms\n",
      "172: 640x640 1 person, 1344.0ms\n",
      "173: 640x640 1 person, 1344.0ms\n",
      "174: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "175: 640x640 1 person, 1 sports ball, 1 baseball glove, 1344.0ms\n",
      "176: 640x640 1 person, 1344.0ms\n",
      "177: 640x640 1 person, 1 sports ball, 1 baseball glove, 1344.0ms\n",
      "178: 640x640 1 person, 1 sports ball, 1 baseball glove, 1344.0ms\n",
      "179: 640x640 1 person, 1344.0ms\n",
      "180: 640x640 1 person, 1 car, 1344.0ms\n",
      "181: 640x640 1 person, 1344.0ms\n",
      "182: 640x640 1 person, 1344.0ms\n",
      "183: 640x640 1 person, 1 car, 1344.0ms\n",
      "184: 640x640 1 person, 1344.0ms\n",
      "185: 640x640 1 person, 1344.0ms\n",
      "186: 640x640 1 person, 1344.0ms\n",
      "187: 640x640 1 person, 1344.0ms\n",
      "188: 640x640 1 person, 1344.0ms\n",
      "189: 640x640 1 person, 1344.0ms\n",
      "190: 640x640 1 person, 1344.0ms\n",
      "191: 640x640 1 person, 1344.0ms\n",
      "192: 640x640 1 person, 1344.0ms\n",
      "193: 640x640 1 person, 1344.0ms\n",
      "194: 640x640 1 person, 1344.0ms\n",
      "195: 640x640 1 person, 1344.0ms\n",
      "196: 640x640 1 fire hydrant, 1344.0ms\n",
      "197: 640x640 1 person, 1344.0ms\n",
      "198: 640x640 1 person, 1344.0ms\n",
      "199: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "200: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "201: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "202: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "203: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "204: 640x640 1 person, 1344.0ms\n",
      "205: 640x640 1 person, 1344.0ms\n",
      "206: 640x640 1 fire hydrant, 1344.0ms\n",
      "207: 640x640 1 person, 1344.0ms\n",
      "208: 640x640 1 person, 1344.0ms\n",
      "209: 640x640 1 person, 1344.0ms\n",
      "210: 640x640 1 person, 1344.0ms\n",
      "211: 640x640 1 person, 1344.0ms\n",
      "212: 640x640 1 person, 1344.0ms\n",
      "213: 640x640 1 person, 1344.0ms\n",
      "214: 640x640 1 person, 1344.0ms\n",
      "215: 640x640 1 person, 1344.0ms\n",
      "216: 640x640 1 person, 1344.0ms\n",
      "217: 640x640 1 person, 1344.0ms\n",
      "218: 640x640 1 person, 1344.0ms\n",
      "219: 640x640 1 person, 1344.0ms\n",
      "220: 640x640 1 fire hydrant, 1344.0ms\n",
      "221: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "222: 640x640 1 person, 1344.0ms\n",
      "223: 640x640 1 person, 1 car, 1 baseball glove, 1344.0ms\n",
      "224: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "225: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "226: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "227: 640x640 2 persons, 1 baseball glove, 1344.0ms\n",
      "228: 640x640 1 person, 1 car, 1344.0ms\n",
      "229: 640x640 1 person, 1344.0ms\n",
      "230: 640x640 1 person, 1344.0ms\n",
      "231: 640x640 1 person, 2 cars, 1344.0ms\n",
      "232: 640x640 2 cars, 1 fire hydrant, 1344.0ms\n",
      "233: 640x640 1 person, 1344.0ms\n",
      "234: 640x640 2 persons, 1344.0ms\n",
      "235: 640x640 1 person, 1 tennis racket, 1344.0ms\n",
      "236: 640x640 1 person, 1 tennis racket, 1344.0ms\n",
      "237: 640x640 1 person, 1 sports ball, 1344.0ms\n",
      "238: 640x640 1 person, 1344.0ms\n",
      "239: 640x640 1 person, 1344.0ms\n",
      "240: 640x640 1 person, 1344.0ms\n",
      "241: 640x640 1 person, 2 cars, 1344.0ms\n",
      "242: 640x640 1 person, 1 car, 1344.0ms\n",
      "243: 640x640 3 persons, 1344.0ms\n",
      "244: 640x640 1 car, 1 fire hydrant, 1344.0ms\n",
      "245: 640x640 1 person, 1 car, 1344.0ms\n",
      "246: 640x640 1 person, 1 car, 1 baseball glove, 1344.0ms\n",
      "247: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "248: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "249: 640x640 1 person, 1 baseball glove, 1344.0ms\n",
      "Speed: 4.3ms preprocess, 1344.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "allImages = False\n",
    "epoch = 250\n",
    "data = images_paths if allImages else images_paths[:epoch]\n",
    "frames_analyzed = len(data)\n",
    "\n",
    "yolo_v8_results = yolo_v8.predict(data)\n",
    "yolo_world_results = yolo_world.predict(data)\n",
    "rt_detr_results = rt_detr.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ThvdjZrm4tq6"
   },
   "outputs": [],
   "source": [
    "class Annotation:\n",
    "    def __init__(self, label, bbox, conf = None):\n",
    "        self.label = label\n",
    "        self.bbox = bbox\n",
    "        self.conf = conf\n",
    "\n",
    "def getFrameId(image_path):\n",
    "    pattern = r'frame-(\\w+)-(\\w+).jpg'\n",
    "    matchedPattern = re.search(pattern, image_path)\n",
    "\n",
    "    if matchedPattern:\n",
    "        return matchedPattern.group(2)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getFrameAnnotations(frameId):\n",
    "    frame = next((frame for frame in frames_annotations if frame['datasetFrameId'] == frameId), None)\n",
    "\n",
    "    if frame:\n",
    "        return frame['annotations']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getFrameSize(frameId):\n",
    "    frame = next((frame for frame in frames_annotations if frame['datasetFrameId'] == frameId), None)\n",
    "\n",
    "    if frame:\n",
    "        return frame['width'], frame['height']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def denormalize(x, y, w, h, image_width, image_height):\n",
    "    denorm_x = x * image_width\n",
    "    denorm_y = y * image_height\n",
    "    denorm_w = w * image_width\n",
    "    denorm_h = h * image_height\n",
    "    return denorm_x, denorm_y, denorm_w, denorm_h\n",
    "\n",
    "def normalize(x, y, w, h, image_width, image_height):\n",
    "    norm_x = x / image_width\n",
    "    norm_y = y / image_height\n",
    "    norm_w = w / image_width\n",
    "    norm_h = h / image_height\n",
    "    return norm_x, norm_y, norm_w, norm_h\n",
    "\n",
    "def yolobbox2bbox(x,y,w,h):\n",
    "    x1, y1 = x-w/2, y-h/2\n",
    "    x2, y2 = x+w/2, y+h/2\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def getIdByLabel(label):\n",
    "    for category_id, category_label in dataset_classes.items():\n",
    "        if category_label == label:\n",
    "            return category_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ay4UFAP-pF9u"
   },
   "outputs": [],
   "source": [
    "def getExpectedAnnotationsAndClasses(frameId, logs = False):\n",
    "  expected_annotations = []\n",
    "  expected_classes = {}\n",
    "  annotations = getFrameAnnotations(frameId)\n",
    "  width, height = getFrameSize(frameId)\n",
    "\n",
    "  print('\\nExpected Annotations: ') if logs else None\n",
    "  for annotation in annotations:\n",
    "      label = annotation['labels'][0]\n",
    "\n",
    "      if label in expected_classes:\n",
    "          expected_classes[label] += 1\n",
    "      else:\n",
    "          expected_classes[label] = 1\n",
    "\n",
    "      bbox = [int(annotation['boundingBox']['x']), int(annotation['boundingBox']['y']), int(annotation['boundingBox']['w']), int(annotation['boundingBox']['h'])]\n",
    "\n",
    "      coco_bbox = BoundingBox.from_coco(*bbox, image_size=(width, height))\n",
    "      x,y,w,h = coco_bbox.to_yolo(return_values=True)\n",
    "      expected_annotations.append(Annotation(label,[x,y,w,h]))\n",
    "\n",
    "      if logs:\n",
    "        x,y,w,h = denormalize(x,y,w,h,width,height)\n",
    "        print(f\"> Bounding Box: x={x}, y={y}, w={w}, h={h}, Label: {label}\")\n",
    "\n",
    "  return expected_annotations, expected_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xs3ymrINqYUS"
   },
   "outputs": [],
   "source": [
    "def getPredictedAnnotationsAndClasses(frameId, result, annotator, logs = False):\n",
    "  preticted_annotations = []\n",
    "  preticted_classes = {}\n",
    "  width, height = getFrameSize(frameId)\n",
    "\n",
    "  print('\\nPreticted Annotations: ') if logs else None\n",
    "  for box in result.boxes:\n",
    "    xyxy = box.xyxy[0]  # get box coordinates in (left, top, right, bottom) format\n",
    "    xywh = box.xywh[0]  # get box coordinates in (x, y, w, h) format\n",
    "    x,y,w,h = float(xywh[0]), float(xywh[1]), float(xywh[2]), float(xywh[3])\n",
    "    \n",
    "    conf = float(box.conf)\n",
    "\n",
    "    labelId = box.cls\n",
    "    label = yolo_v8.names[int(labelId)]\n",
    "    \n",
    "    if label in preticted_classes:\n",
    "          preticted_classes[label] += 1\n",
    "    else:\n",
    "          preticted_classes[label] = 1\n",
    "\n",
    "    if logs:\n",
    "      annotator.box_label(xyxy, label)\n",
    "      print(f\"> Bounding Box: x={round(x,1)}, y={round(y,1)}, w={round(w,1)}, h={round(h,1)}, Label: {label}, Conf: {conf}\")\n",
    "\n",
    "    x,y,w,h = normalize(x,y,w,h,width,height)\n",
    "    preticted_annotations.append(Annotation(label,[x,y,w,h], conf))\n",
    "\n",
    "  return preticted_annotations, preticted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "YY98KSi-u5TK"
   },
   "outputs": [],
   "source": [
    "def calculateCorrectPredictionsAndClasses(frameId, predicted_annotations, expected_annotations, iou_threshold = 0.5):\n",
    "  correct_predictions = 0\n",
    "  correct_classes = {}\n",
    "  width, height = getFrameSize(frameId)\n",
    "\n",
    "  #tp = []\n",
    "  #conf = [] \n",
    "  #pred_cls = [] \n",
    "  #target_cls = [] \n",
    "\n",
    "  for predicted in predicted_annotations:\n",
    "    preticted_bbox = BoundingBox.from_yolo(*predicted.bbox, image_size=(width, height))\n",
    "\n",
    "    best_expected_iou = 0\n",
    "    best_expected_annotation_index = None\n",
    "\n",
    "    for index, expected in enumerate(expected_annotations):\n",
    "      if expected.label == predicted.label:\n",
    "        expected_bbox = BoundingBox.from_yolo(*expected.bbox, image_size=(width, height))\n",
    "        iou = preticted_bbox.iou(expected_bbox)\n",
    "        if (iou > best_expected_iou):\n",
    "          best_expected_iou = iou\n",
    "          best_expected_annotation_index = index\n",
    "\n",
    "    if(best_expected_iou >= iou_threshold):\n",
    "      removed_annotation = expected_annotations.pop(best_expected_annotation_index)\n",
    "      correct_predictions += 1\n",
    "\n",
    "      #target_cls.append(removed_annotation.label)\n",
    "      #tp.append(True)\n",
    "      \n",
    "      if predicted.label in correct_classes:\n",
    "          correct_classes[predicted.label] += 1\n",
    "      else:\n",
    "          correct_classes[predicted.label] = 1\n",
    "    #else:\n",
    "      #tp.append(False)\n",
    "      #target_cls.append(\"background\") #!classe fittizia\n",
    "      \n",
    "    #conf.append(predicted.conf)\n",
    "    #pred_cls.append(predicted.label)\n",
    "    \n",
    "\n",
    "  return correct_predictions, correct_classes #, tp, conf, pred_cls, target_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JWhHDx5kZRRy"
   },
   "outputs": [],
   "source": [
    "def analyzeResults(results, verboseLogs, frameLogs):\n",
    "  metric = Metric()\n",
    "\n",
    "  total_precision = 0\n",
    "  total_recall = 0\n",
    "  total_f1_score = 0\n",
    "\n",
    "  total_class_metrics = {label: {\"precisions\": [], \"recalls\": [], \"f1-scores\": []} for label in dataset_classes.values()}\n",
    "  \n",
    "  for index, result in enumerate(results):\n",
    "      frameId = getFrameId(images_paths[index])\n",
    "\n",
    "      if verboseLogs:\n",
    "        print('\\n----------------------------------------------------------------------------')\n",
    "        print(f'\\nFrame ID: \"{frameId}\"')\n",
    "\n",
    "      annotator = Annotator(cv2.imread(images_paths[index]))\n",
    "\n",
    "      expected_annotations, expected_classes = getExpectedAnnotationsAndClasses(frameId, verboseLogs)\n",
    "      preticted_annotations, preticted_classes = getPredictedAnnotationsAndClasses(frameId, result, annotator, verboseLogs)\n",
    "\n",
    "      if verboseLogs:\n",
    "        print('\\n')\n",
    "        cv2_imshow(annotator.result())\n",
    "\n",
    "      total_predictions = len(preticted_annotations)\n",
    "      #correct_predictions, correct_classes, tp, conf, pred_cls, target_cls = calculateCorrectPredictionsAndClasses(frameId, preticted_annotations, expected_annotations)\n",
    "      #apc = ap_per_class(np.array(tp, dtype=np.bool_), np.array(conf), np.array(pred_cls), np.array(target_cls))\n",
    "      correct_predictions, correct_classes = calculateCorrectPredictionsAndClasses(frameId, preticted_annotations, expected_annotations)\n",
    "      wrong_predictions = total_predictions - correct_predictions\n",
    "      missing_predictions = len(expected_annotations)\n",
    "\n",
    "      if verboseLogs:\n",
    "        print(\"\\nTotal Predictions: \", total_predictions) # true positives + false positives\n",
    "        print(\"Correct Predictions: \", correct_predictions) # true positives\n",
    "        print(\"Wrong Predictions: \", wrong_predictions) # false positives\n",
    "        print(\"Missing Predictions: \", missing_predictions) # false negatives\n",
    "\n",
    "      precision = (correct_predictions / total_predictions) if total_predictions > 0 else 0\n",
    "      recall = (correct_predictions / (correct_predictions + missing_predictions)) if correct_predictions + missing_predictions > 0 else 0\n",
    "      f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "      if verboseLogs:\n",
    "        print(f'\\nPrecision: {round(precision * 100, 2)}%')\n",
    "        print(f'Recall: {round(recall * 100, 2)}%')\n",
    "        print(f'F1-Score: {round(f1_score * 100, 2)}%')\n",
    "      elif frameLogs:\n",
    "        print(f'Frame \"{frameId}\" | Precision: {round(precision * 100, 2)}% | Recall: {round(recall * 100, 2)}% | F1-Score: {round(f1_score * 100, 2)}%')\n",
    "\n",
    "      total_precision += precision\n",
    "      total_recall += recall\n",
    "      total_f1_score += f1_score\n",
    "\n",
    "      class_metrics = {}\n",
    "\n",
    "      for label in expected_classes:\n",
    "        class_metrics[label] = {\"precision\": 0, \"recall\": 0, \"f1-score\": 0}\n",
    "\n",
    "        y_true = []\n",
    "        y_score = []\n",
    "\n",
    "        expected = expected_classes.get(label, 0)\n",
    "        preticted = preticted_classes.get(label, 0)\n",
    "        correct = correct_classes.get(label, 0) # TPma gli \n",
    "        wrong = preticted - correct # FP\n",
    "        missing = expected - correct # FN\n",
    "\n",
    "        class_precision = correct / (correct + wrong) if (correct + wrong) > 0 else 0\n",
    "        class_recall = correct / (correct + missing) if (correct + missing) > 0 else 0\n",
    "        class_f1_score = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "\n",
    "        if verboseLogs:\n",
    "          print(f'Class \"{label}\" | Precision: {round(class_precision * 100, 2)}% | Recall: {round(class_recall * 100, 2)}% | F1-Score: {round(class_f1_score * 100, 2)}%')\n",
    "\n",
    "        class_metrics[label]['precision'] = class_precision\n",
    "        class_metrics[label]['recall'] = class_recall\n",
    "        class_metrics[label]['f1-score'] = class_f1_score\n",
    "\n",
    "    \n",
    "\n",
    "      for label in class_metrics:\n",
    "        total_class_metrics[label]['precisions'].append(class_metrics[label]['precision'])\n",
    "        total_class_metrics[label]['recalls'].append(class_metrics[label]['recall'])\n",
    "        total_class_metrics[label]['f1-scores'].append(class_metrics[label]['f1-score'])\n",
    "\n",
    "  print('----------------------------------------------------------------------------') if frameLogs else None\n",
    "\n",
    "  avg_precision = total_precision / frames_analyzed\n",
    "  avg_recall = total_recall / frames_analyzed\n",
    "  avg_f1_score = total_f1_score / frames_analyzed\n",
    "\n",
    "  avg_class_metrics = {}\n",
    "  \n",
    "  for label in total_class_metrics:\n",
    "    if len(total_class_metrics[label][\"precisions\"]) > 0:\n",
    "      avg_class_metrics[label] = {\"precision\": 0, \"recall\": 0, \"f1-score\": 0}\n",
    "      avg_class_metrics[label][\"precision\"] = sum(total_class_metrics[label][\"precisions\"]) / len(total_class_metrics[label][\"precisions\"])\n",
    "      avg_class_metrics[label][\"recall\"] = sum(total_class_metrics[label][\"recalls\"]) / len(total_class_metrics[label][\"recalls\"])\n",
    "      avg_class_metrics[label][\"f1-score\"] = sum(total_class_metrics[label][\"f1-scores\"]) / len(total_class_metrics[label][\"f1-scores\"])\n",
    "\n",
    "  #print(avg_class_metrics)\n",
    "\n",
    "  return avg_precision, avg_recall, avg_f1_score, avg_class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanAveragePrecision(results, iou_threshold = 0.5):\n",
    "  \n",
    "  class_y_data = {label: {'y_true': [], 'y_scores': []} for label in dataset_classes.values()}\n",
    "  \n",
    "  for index, result in enumerate(results):\n",
    "      frameId = getFrameId(images_paths[index])\n",
    "      width, height = getFrameSize(frameId)\n",
    "      annotations = getFrameAnnotations(frameId)\n",
    "\n",
    "      expected_annotations = []\n",
    "      for annotation in annotations:\n",
    "          label = annotation['labels'][0]\n",
    "          bbox = [int(annotation['boundingBox']['x']), int(annotation['boundingBox']['y']), int(annotation['boundingBox']['w']), int(annotation['boundingBox']['h'])]\n",
    "          coco_bbox = BoundingBox.from_coco(*bbox, image_size=(width, height))\n",
    "          x,y,w,h = coco_bbox.to_yolo(return_values=True)\n",
    "          expected_annotations.append(Annotation(label,[x,y,w,h]))    \n",
    "    \n",
    "      predicted_annotations = []\n",
    "      for box in result.boxes:\n",
    "        xywh = box.xywh[0]\n",
    "        x,y,w,h = float(xywh[0]), float(xywh[1]), float(xywh[2]), float(xywh[3])\n",
    "        conf = float(box.conf)\n",
    "        labelId = box.cls\n",
    "        label = yolo_v8.names[int(labelId)]\n",
    "        x,y,w,h = normalize(x,y,w,h,width,height)\n",
    "        predicted_annotations.append(Annotation(label,[x,y,w,h], conf))\n",
    "    \n",
    "    \n",
    "      for predicted in predicted_annotations:\n",
    "        preticted_bbox = BoundingBox.from_yolo(*predicted.bbox, image_size=(width, height))\n",
    "    \n",
    "        best_expected_iou = 0\n",
    "        best_expected_annotation_index = None\n",
    "    \n",
    "        for index, expected in enumerate(expected_annotations):\n",
    "          if expected.label == predicted.label:\n",
    "            expected_bbox = BoundingBox.from_yolo(*expected.bbox, image_size=(width, height))\n",
    "            iou = preticted_bbox.iou(expected_bbox)\n",
    "            if (iou > best_expected_iou):\n",
    "              best_expected_iou = iou\n",
    "              best_expected_annotation_index = index\n",
    "    \n",
    "        if(best_expected_iou >= iou_threshold):\n",
    "          removed_annotation = expected_annotations.pop(best_expected_annotation_index)\n",
    "          # aggiunge TP ad y_true della classe\n",
    "          class_y_data[predicted.label]['y_true'].append(1)\n",
    "          class_y_data[predicted.label]['y_scores'].append(predicted.conf)\n",
    "        else:\n",
    "          # aggiunge FP ad y_true della classe erroneamente detectata (se presente nel dataset, altrimenti a 'wrong')\n",
    "          if label in class_y_data:\n",
    "              class_y_data[label]['y_true'].append(0)\n",
    "              class_y_data[label]['y_scores'].append(predicted.conf)\n",
    "          else:\n",
    "              class_y_data['wrong']['y_true'].append(0)\n",
    "              class_y_data['wrong']['y_scores'].append(predicted.conf)\n",
    "\n",
    "      #for expected in expected_annotations:\n",
    "        # aggiunge FN ad y_true della classe\n",
    "        #class_y_data[expected.label]['y_true'].append(0)\n",
    "        #class_y_data[expected.label]['y_scores'].append(0)\n",
    "\n",
    "  class_y_data_filtered = {\n",
    "    label: data for label, data in class_y_data.items() \n",
    "    if any(data['y_true']) and any(data['y_scores']) and label != 'wrong'\n",
    "       and not all(value == 0 for value in data['y_true'])\n",
    "       and not all(value == 0 for value in data['y_scores'])\n",
    "  }\n",
    "\n",
    "  ap_values = []\n",
    "\n",
    "  for label, data in class_y_data_filtered.items():\n",
    "      y_true = data['y_true']\n",
    "      y_scores = data['y_scores']\n",
    "\n",
    "      y_true_sorted = [y_true[idx] for idx in sorted(range(len(y_scores)), key=lambda i: y_scores[i], reverse=True)]\n",
    "      y_scores_sorted = sorted(y_scores, reverse=True)\n",
    "      #print(label, y_true_sorted, y_scores_sorted )\n",
    "\n",
    "      precision, recall, _ = precision_recall_curve(y_true_sorted, y_scores_sorted)\n",
    "      plt.plot(recall, precision, marker='.')\n",
    "      plt.xlabel('Recall')\n",
    "      plt.ylabel('Precision')\n",
    "      plt.title('Precision-Recall Curve for class \"'+label+'\"')\n",
    "      plt.grid(True)\n",
    "      plt.show()\n",
    "    \n",
    "      ap = average_precision_score(y_true, y_scores)\n",
    "      print(f\"AP for class '{label}': {ap:.4f}\")\n",
    "      ap_values.append(ap)\n",
    "\n",
    "  mAP = sum(ap_values) / len(ap_values)\n",
    "  print(f\"mAP: {mAP:.4f}\")\n",
    "\n",
    "  return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculateMeanAveragePrecision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m yolo_v8_mAP \u001B[38;5;241m=\u001B[39m \u001B[43mcalculateMeanAveragePrecision\u001B[49m(yolo_v8_results)\n\u001B[1;32m      2\u001B[0m yolo_world_map \u001B[38;5;241m=\u001B[39m calculateMeanAveragePrecision(yolo_world_results)\n\u001B[1;32m      3\u001B[0m rt_detr_map \u001B[38;5;241m=\u001B[39m calculateMeanAveragePrecision(rt_detr_results)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'calculateMeanAveragePrecision' is not defined"
     ]
    }
   ],
   "source": [
    "yolo_v8_mAP = calculateMeanAveragePrecision(yolo_v8_results)\n",
    "yolo_world_map = calculateMeanAveragePrecision(yolo_world_results)\n",
    "rt_detr_map = calculateMeanAveragePrecision(rt_detr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0fOCspI75fk",
    "outputId": "e03b07a2-1987-445e-c764-f76c254eff65"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_v8_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m verboseLogs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m      2\u001B[0m frameLogs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m yolo_v8_avg_precision, yolo_v8_avg_recall, yolo_v8_avg_f1_score, yolo_v8_avg_class_metrics \u001B[38;5;241m=\u001B[39m analyzeResults(\u001B[43myolo_v8_results\u001B[49m, verboseLogs, frameLogs)\n\u001B[1;32m      5\u001B[0m yolo_world_avg_precision, yolo_world_avg_recall, yolo_world_avg_f1_score, yolo_world_avg_class_metrics \u001B[38;5;241m=\u001B[39m analyzeResults(yolo_world_results, verboseLogs, frameLogs)\n\u001B[1;32m      6\u001B[0m rt_detr_avg_precision, rt_detr_avg_recall, rt_detr_avg_f1_score, rt_detr_avg_class_metrics \u001B[38;5;241m=\u001B[39m analyzeResults(rt_detr_results, verboseLogs, frameLogs)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'yolo_v8_results' is not defined"
     ]
    }
   ],
   "source": [
    "verboseLogs = False\n",
    "frameLogs = False\n",
    "\n",
    "yolo_v8_avg_precision, yolo_v8_avg_recall, yolo_v8_avg_f1_score, yolo_v8_avg_class_metrics = analyzeResults(yolo_v8_results, verboseLogs, frameLogs)\n",
    "yolo_world_avg_precision, yolo_world_avg_recall, yolo_world_avg_f1_score, yolo_world_avg_class_metrics = analyzeResults(yolo_world_results, verboseLogs, frameLogs)\n",
    "rt_detr_avg_precision, rt_detr_avg_recall, rt_detr_avg_f1_score, rt_detr_avg_class_metrics = analyzeResults(rt_detr_results, verboseLogs, frameLogs)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------') if verboseLogs else None\n",
    "\n",
    "print(f'Total Frames: {frames_analyzed}')\n",
    "print(f'YOLOv8    | Precision: {round(yolo_v8_avg_precision * 100, 2)}% | Recall: {round(yolo_v8_avg_recall * 100, 2)}% | F1-Score: {round(yolo_v8_avg_f1_score * 100, 2)}%')\n",
    "print(f'YOLOworld | Precision: {round(yolo_world_avg_precision * 100, 2)}% | Recall: {round(yolo_world_avg_recall * 100, 2)}% | F1-Score: {round(yolo_world_avg_f1_score * 100, 2)}%')\n",
    "print(f'RT-DETR   | Precision: {round(rt_detr_avg_precision * 100, 2)}% | Recall: {round(rt_detr_avg_recall * 100, 2)}% | F1-Score: {round(rt_detr_avg_f1_score * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fPJGJJUXLQ-b"
   },
   "outputs": [],
   "source": [
    "def getConfusionMatrix(results):\n",
    "  cm = ConfusionMatrix(len(dataset_classes))\n",
    "\n",
    "  for index, result in enumerate(results):\n",
    "    frameId = getFrameId(images_paths[index])\n",
    "    width, height = getFrameSize(frameId)\n",
    "    annotations = getFrameAnnotations(frameId)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------')\n",
    "    print(f'\\nFrame ID: \"{frameId}\"')\n",
    "\n",
    "    annotator = Annotator(cv2.imread(images_paths[index]))\n",
    "\n",
    "    expected_annotations = []\n",
    "    gt_bboxes = []\n",
    "    gt_cls = []\n",
    "    ''' gt_bboxes = np.empty((0, 4))\n",
    "    gt_cls = np.empty((0, 1)) '''\n",
    "\n",
    "    print('\\nExpected Annotations: ')\n",
    "    for annotation in annotations:\n",
    "      label = annotation['labels'][0]\n",
    "      labelId = getIdByLabel(label)\n",
    "      bbox = [int(annotation['boundingBox']['x']), int(annotation['boundingBox']['y']), int(annotation['boundingBox']['w']), int(annotation['boundingBox']['h'])]\n",
    "      coco_bbox = BoundingBox.from_coco(*bbox, image_size=(width, height))\n",
    "      x,y,w,h = coco_bbox.to_yolo(return_values=True)\n",
    "      x,y,w,h = denormalize(x,y,w,h,width,height)\n",
    "      x1,y1,x2,y2 = yolobbox2bbox(x,y,w,h)\n",
    "\n",
    "      print(f\"> Bbox: {x1,y1,x2,y2}, Label: {labelId}-{label}\")\n",
    "      expected_annotations.append(Annotation(label,[x1,y1,x2,y2]))\n",
    "      gt_bbox = torch.tensor([x1, y1, x2, y2])\n",
    "      gt_bboxes.append(gt_bbox)\n",
    "      gt_cls.append(labelId)\n",
    "\n",
    "      ''' gt_bbox = np.array([x1, y1, x2, y2])\n",
    "      gt_bboxes = np.vstack((gt_bboxes, gt_bbox))\n",
    "      gt_cls = np.vstack((gt_cls, label)) '''\n",
    "\n",
    "    gt_bboxes = torch.stack(gt_bboxes)\n",
    "    gt_cls = torch.tensor(gt_cls)\n",
    "\n",
    "    preticted_annotations = []\n",
    "    detections = []\n",
    "    ''' detections = np.empty((0, 6)) '''\n",
    "\n",
    "    print('\\nPreticted Annotations: ')\n",
    "    for box in result.boxes:\n",
    "      labelId = int(box.cls) + 1\n",
    "      label = str(yolo_v8.names[labelId - 1])\n",
    "      conf = float(box.conf[0])\n",
    "      xyxy = box.xyxy[0]\n",
    "      annotator.box_label(xyxy, label)\n",
    "      x1,y1,x2,y2 = float(xyxy[0]), float(xyxy[1]), float(xyxy[2]), float(xyxy[3])\n",
    "      print(f\"> Bbox: {x1,y1,x2,y2}, Label: {labelId}-{label}, Conf: {conf}\")\n",
    "      preticted_annotations.append(Annotation(label,[x1,y1,x2,y2]))\n",
    "      detection = torch.tensor([x1, y1, x2, y2, conf, labelId])\n",
    "      detections.append(detection)\n",
    "      ''' detection = np.array([x1, y1, x2, y2, conf, label], dtype=object)\n",
    "      detections = np.vstack((detections, detection)) '''\n",
    "\n",
    "    if len(detections) == 0:\n",
    "      detections = torch.empty((0, 6))\n",
    "    else:\n",
    "      detections = torch.stack(detections)\n",
    "\n",
    "    '''  print(gt_bboxes)\n",
    "    print(gt_cls)\n",
    "    print(detections) '''\n",
    "\n",
    "    cm.process_batch(detections, gt_bboxes, gt_cls)\n",
    "    #cv2_imshow(annotator.result())\n",
    "\n",
    "\n",
    "\n",
    "  return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "vNdP22lo-eul",
    "outputId": "212ec28d-3246-477f-ed16-dfbe02bc1f58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' yolo_v8_cm.print()\\nyolo_v8_cm.plot(True,\"/\", (\\'label1\\',\\'label2\\')) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yolo_v8_cm = getConfusionMatrix(yolo_v8_results)\n",
    "\n",
    "''' yolo_v8_cm.print()\n",
    "yolo_v8_cm.plot(True,\"/\", ('label1','label2')) '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
